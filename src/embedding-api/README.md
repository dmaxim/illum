# Embedding API

FastAPI application for downloading document chunks from Azure Blob Storage, generating embeddings, and writing embedded chunks back to storage.

## Overview

This API provides an endpoint to download pre-chunked document files from Azure Blob Storage based on a document ID, generate embeddings using Azure OpenAI, and write the embedded chunks (including the embedding vectors) to a destination container. The chunks are generated by the `chunk-api` project and stored in a structured format in blob storage.

## Features

- Download all chunk files for a given document from Azure Blob Storage
- Parse chunk JSON files into structured data models
- Generate embeddings for each chunk using Azure OpenAI
- Write embedded chunks to destination container with embeddings as list of floats
- Azure authentication using DefaultAzureCredential
- Rate limiting and retry logic for Azure OpenAI API calls
- Batch processing for efficient embedding generation

## Prerequisites

- Python 3.11+
- Azure Storage Account with chunks container and embedding container
- Azure OpenAI resource with embedding deployment
- Azure authentication configured (Azure CLI, Managed Identity, etc.)

## Installation

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Create a `.env` file based on `.env.example`:
```bash
cp .env.example .env
```

3. Configure environment variables in `.env`:
```bash
# Azure Blob Storage
AZURE_STORAGE_ACCOUNT=your_storage_account_name
AZURE_STORAGE_CHUNKS_CONTAINER=your_chunks_container_name
AUZRE_STORAGE_EMBEDDING_CONTAINER=your_embedding_container_name

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your_api_key
AZURE_OPENAI_VERSION=2024-02-01
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=your_embedding_deployment_name

# API
PORT=8002
```

## Running the API

### Development
```bash
python main.py
```

Or using uvicorn directly:
```bash
uvicorn main:app --reload --port 8002
```

### Production
```bash
uvicorn main:app --host 0.0.0.0 --port 8002
```

## API Endpoints

### POST /embed

Downloads chunk files, generates embeddings, and writes embedded chunks to storage.

**Request Body:**
```json
{
  "document_id": "9b7b3e33-07da-4fe5-9467-6de3074e26c9",
  "document_name": "Montana-RFP.pdf",
  "total_pages": 24,
  "total_chunks": 50,
  "year": 2025,
  "location": "Montana",
  "doc_type": "request"
}
```

**Response:**
```json
{
  "document_id": "9b7b3e33-07da-4fe5-9467-6de3074e26c9",
  "document_name": "Montana-RFP.pdf",
  "total_pages": 24,
  "total_chunks": 50,
  "year": 2025,
  "location": "Montana",
  "doc_type": "request",
  "chunks": [
    {
      "chunk_id": "9b7b3e33-07da-4fe5-9467-6de3074e26c9_0",
      "chunk_index": 0,
      "page_number": 1,
      "content": "NEMT Solicitation Scope of Work...",
      "metadata": {
        "producer": "macOS Version 26.1",
        "creator": "Word",
        "location": "Montana",
        "year": 2025,
        "doc_type": "request",
        "document_id": "9b7b3e33-07da-4fe5-9467-6de3074e26c9",
        "chunk_size": 250,
        "chunk_overlap": 25
      }
    }
  ],
  "message": "Embedded 50 chunks and wrote to container 'your_embedding_container_name'"
}
```

**Note:** The response includes chunk metadata but not the embedding vectors (which can be large). The embeddings are written to the destination container.

### GET /health

Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "azure_blob_config": "configured",
  "azure_openai_config": "configured"
}
```

## Azure Blob Storage Structure

### Source Container (Chunks)
The API reads chunks from the following structure:
```
{document_id}/
  chunks/
    chunk_000000.json
    chunk_000001.json
    chunk_000002.json
    ...
```

Each input chunk file contains:
- `chunk_id`: Unique identifier
- `chunk_index`: Sequential index
- `page_number`: Source page number
- `content`: Text content of the chunk
- `metadata`: Document and chunk metadata

### Destination Container (Embeddings)
The API writes embedded chunks to:
```
{document_id}/
  chunk-0.json
  chunk-1.json
  chunk-2.json
  ...
```

Each output embedded chunk file contains all the above fields plus:
- `embedding`: List of floats representing the embedding vector (e.g., 1536 dimensions for text-embedding-ada-002)

## Authentication

This API uses Azure's `DefaultAzureCredential` for authentication, which supports:
- Azure CLI authentication
- Managed Identity
- Environment variables
- Visual Studio Code
- And more...

For local development, ensure you're logged in via Azure CLI:
```bash
az login
```

## Error Handling

The API returns appropriate HTTP status codes:
- `200`: Success
- `404`: Document or chunks not found
- `500`: Server error or configuration issue

## Integration with chunk-api

This API works alongside the `chunk-api` project:
1. `chunk-api` processes documents and writes chunk files to Azure Blob Storage (source container)
2. `embedding-api` reads those chunk files, generates embeddings using Azure OpenAI, and writes embedded chunks to the destination container
3. The embedded chunks can then be used for vector database ingestion or other downstream processing

## Embedding Process

1. **Download**: Fetches all chunk JSON files for a document from the source container
2. **Generate**: Uses Azure OpenAI embedding model to generate vector embeddings for each chunk's content
3. **Write**: Writes each chunk with its embedding to the destination container
   - Format: `{document_id}/chunk-{chunkIndex}.json`
   - Includes all original chunk data plus `embedding` field
4. **Batch Processing**: Processes chunks in batches (default 100) to optimize API usage
5. **Rate Limiting**: Implements exponential backoff and pausing to handle rate limits

## Future Enhancements

- Direct vector database integration (e.g., Pinecone, Weaviate, Azure AI Search)
- Support for different embedding models and providers
- Caching of downloaded chunks
- Progress tracking for long-running embedding jobs
- Webhook notifications on completion
- Parallel processing for multiple documents
